{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7347112-d921-4122-97d6-6578178bb882",
   "metadata": {},
   "source": [
    "## __1. Train-Test split__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b87789-2307-48ba-b32b-7bfe349cfbaf",
   "metadata": {},
   "source": [
    "Train test split is a model validation procedure that allows you to simulate how a model would perform on new/unseen data by splitting a dataset into a training set and a testing set. \n",
    "\n",
    "- The training set is data used to train the model, and the testing set data (which is new to the model) is used to test the modelâ€™s performance and accuracy.\n",
    "- A train test split can also involve splitting data into a validation set, which is data used to fine-tune hyperparameters and optimize the model during the training process.\n",
    "\n",
    "<img src=\"https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_train-test-split_0.jpg\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc680f-078e-49b8-8129-50974d82cb2c",
   "metadata": {},
   "source": [
    "#### __Methods for Splitting Data in a Train Test Split__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb30af-4208-4474-962e-951975c0eb44",
   "metadata": {},
   "source": [
    "Some common methods of splitting data in a train test split:\n",
    "\n",
    "1. __Random Splitting:__ involves randomly shuffling data and splitting it into training and testing sets based on given percentages (like 75% training and 25% testing).\n",
    "   \n",
    "2. __Stratified Splitting:__ divides a dataset in a way that preserves its proportion of classes or categories. This creates training and testing sets with class proportions representative of the original dataset. Using stratified splitting can prevent model bias, and is most effective for imbalanced datasets. Use `stratify` parameter in the `train_test_split()` method.\n",
    "\n",
    "3. __Time-Based Splitting:__ involves organizing data in a set by points in time, ensuring past data is in the training set and future or later data is in the testing set. Splitting data based on time works to simulate real-world scenarios (for example, predicting future financial or market trends) and allows for time series analysis on time series datasets. However, one drawback to time-based splitting is that it may not fully capture trends for non-stationary data (data that continually changes over time). In scikit-learn, time series data can be split into training and testing sets by using the `TimeSeriesSplit()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80c08c-d543-4a9f-99d0-26aa5d56fe80",
   "metadata": {},
   "source": [
    "## __2. Data Standardization__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875f4c5-eee1-494c-a408-566bd2bc18dd",
   "metadata": {},
   "source": [
    "Data standardization comes into the picture when features of the input data set have large differences between their ranges, or simply when they are measured in different units. It converts data into a standard, uniform format, making it consistent across different data sets and easier to understand for machine learning or statistical models. \n",
    "\n",
    "- Standardizing data can enhance data quality and accuracy, which helps users make reliable data-driven decisions.\n",
    "- Z-score normalization, or standardization, is one of the most popular methods to standardize data.\n",
    "- With this method, data is transformed to have a mean of 0 and a standard deviation of 1, giving all data points the same scale.\n",
    "- We can use the `StandardScaler()` method from scikit-learn.\n",
    "- `StandardScaler()` provides the 3 methods fit(), transform(), and fit_transform().\n",
    "- `fit()` method - takes the dataset we aim to standardize as an argument and computes its mean and standard deviation.\n",
    "- `transform()` method - applies the scaling performed using the `.fit()` method to every feature value.\n",
    "- `fit_transform()` method - does both `.fit()` and `.transform()`. Has more computational efficiency as it combines two methods into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da23353-7de3-4d2d-945f-3d81bdb0ae49",
   "metadata": {},
   "source": [
    "### __Should we perform `.fit_transform()` before or after the split of training and test data?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdff940-e8a8-4b71-8b86-a316dbf04207",
   "metadata": {},
   "source": [
    "Normalization / Standardization should be done after splitting the data into train and test sets. The reason is to avoid any data leakage. This is also applicable to `CountVectorizer()` where it counts the no. of words in a text message.\n",
    "\n",
    "__Data Leakage:__ Data leakage happens when information from outside the training set is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the model being constructed.\n",
    "\n",
    "The testing data points represent real-world data. Feature normalization (or data standardisation) of the explanatory (or predictor) variables is a technique used to center and normalise the data by subtracting the mean and dividing by the standard deviation. If you take the mean and variance of the whole dataset, you will be introducing future information into the explanatory variables (i.e. the mean and std. deviation). \n",
    "\n",
    "- We perform standardisation as `fit_transform()` on the training set and `transform()` on the testing set.\n",
    "- `fit_transform()` on the train data standardises it and calculates the mean and standard deviation for the train data, `transform()` is used on the test data which means we will apply the metrics calculated from the train set onto the test set. We do so to prevent data leakage, i.e. learning something new from the test data, in order to accurately test the selected model.\n",
    "- Using the `fit_transform` method on the entire dataset could cause the model to overperform, as it would have prior knowledge of the test data vocabulary, leading to an unrealistic assessment of its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6aa9c7-e7c7-4093-a844-b3a507158f28",
   "metadata": {},
   "source": [
    "## __3. Missing data imputation__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41b0d1-0572-4b1a-8ec2-8bb0e7059af3",
   "metadata": {},
   "source": [
    "Missing data imputation is a technique used to fill in missing values within a dataset, preventing potential issues with analysis or model training. It involves replacing missing values with estimated values based on the existing data, ensuring the dataset is complete and usable for further analysis.\n",
    "\n",
    "- __Univariate Imputation:__ This method focuses on a single variable, using the mean, median, or mode of the non-missing values to fill in the missing values for that specific variable. \n",
    "- __Multivariate Imputation:__ This method considers multiple variables to estimate the missing values. It often involves using regression models or other statistical methods to predict the missing values based on the relationships between the variables. \n",
    "- __Multiple Imputation:__ This technique creates multiple imputed datasets by generating different estimates for the missing values. This allows for incorporating uncertainty about the true values, as analysis can be performed separately on each imputed dataset and results can be pooled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911a7e3-2467-4cf6-93f2-8c268507b361",
   "metadata": {},
   "source": [
    "#### __Common Imputation Techniques:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea68ea-f5d2-4108-a413-d7cedf55aef5",
   "metadata": {},
   "source": [
    "1. __Mean, Median, and Mode Imputation:__ Replacing missing values with the average, middle value, or most frequent value, respectively. \n",
    "2. __Constant Value Imputation:__ Replacing missing values with a predetermined constant, which can be a specific value or a value representing an \"unknown\" or \"missing\" category. \n",
    "3. __Regression Imputation:__ Using regression models to predict missing values based on other available variables. \n",
    "4. __K-Nearest Neighbors Imputation:__ Replacing missing values with the average of the values from the nearest neighbors in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f242544-fad9-4db2-9fa9-42bbc0ab68cc",
   "metadata": {},
   "source": [
    "## __4. Cross Validation Techniques__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434f7b3-27d2-4519-a1db-f5c66fbb845f",
   "metadata": {},
   "source": [
    "Cross-validation is a machine learning technique that evaluates model performance on unseen data by dividing the data into multiple folds. In each iteration, one fold is used as a validation set and the remaining as training data. This process is repeated such that each fold serves as the validation set once. The results from all iterations are averaged to provide a robust estimate of model performance. The main purpose of cross validation is to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfa7e6-cc8d-4bb9-be56-bd6f2ed3b062",
   "metadata": {},
   "source": [
    "### __Types of Cross-Validation__\n",
    "\n",
    "Some of the common cross-validation techniques are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddffe3-cc96-4d17-a92f-52bf6c772006",
   "metadata": {},
   "source": [
    "#### __4.1 K-Fold Cross-Validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d27c6-e431-4003-91b1-84908f671d96",
   "metadata": {
    "id": "7rVJTxNaB49j"
   },
   "source": [
    "In K-Fold Cross validation, the dataset is divided into `k` equally sized folds. The model is trained on `k-1` folds and tested on the remaining fold. This process is repeated `k` times, with each fold used exactly once as the test set. The results are averaged to produce a single performance estimate.\n",
    "* Pros: Provides a more accurate estimate of model performance.\n",
    "* Cons: Computationally intensive for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5baa80b-acf3-4a30-bb15-50d0f98014e9",
   "metadata": {},
   "source": [
    "#### __4.2 Stratified K-Fold Cross-Validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3cb97-9d06-49ad-990d-1ea36fe6cad9",
   "metadata": {
    "id": "b_PhSCAdCFUa"
   },
   "source": [
    "It is a technique used in machine learning to ensure that each fold of the cross-validation process maintains the same class distribution as the entire dataset. This is particularly important when dealing with imbalanced datasets where certain classes may be under represented. In this method:\n",
    "- The dataset is divided into k folds while maintaining the proportion of classes in each fold.\n",
    "- During each iteration, one-fold is used for testing and the remaining folds are used for training.\n",
    "- The process is repeated k times with each fold serving as the test set exactly once.\n",
    "  \n",
    "* Pros: More reliable performance estimates for imbalanced datasets.\n",
    "* Cons: Still computationally intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68dbaae-d4de-4650-8d8d-f3ef06fb39b6",
   "metadata": {},
   "source": [
    "#### __4.3 Holdout Method__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c37ab1-5f85-4138-ae44-041509469041",
   "metadata": {
    "id": "VhWbSRE1IPAQ"
   },
   "source": [
    "In holdout method, the dataset is divided into two sets, a training set and a test set, i.e. we perform training on the 50% of the given dataset and rest 50% is used for the testing purpose. The model is trained on the training set and evaluated on the test set.\n",
    "\n",
    "The major drawback of this method is that we perform training on the 50% of the dataset, it may possible that the remaining 50% of the data contains some important information which we are leaving while training our model that can lead to higher bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4498cd9-f0b5-4ae2-88bc-7d7511e4c90f",
   "metadata": {},
   "source": [
    "#### __4.4 Leave-One-Out Cross-Validation (LOOCV)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e7825-8dd7-4f3f-8182-acf8df6a02cb",
   "metadata": {
    "id": "ZEPaQtIICHpx"
   },
   "source": [
    "A special case of k-fold cross-validation where k is equal to the number of data points in the dataset ($k = n$). Each observation is used once as a test set, and the model is trained on all remaining data points. So, model is trained on `k-1` data points and tested using 1 data point.\n",
    "\n",
    "* Pros: Maximizes the amount of training data used.\n",
    "* Cons: Extremely computationally expensive, especially for large datasets. another major drawback of this method is that it leads to higher variation in the testing model as we are testing against one data point. If the data point is an outlier it can lead to higher variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13010326-ee97-4374-ae57-70f12cd92a79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e47efb3-234a-4d3a-87e4-1be4057a89e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b26e5b-1891-472a-bbc1-a6341d4973a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64747f2-b60f-469c-b0b2-df5ff3d439d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b089effa-b9aa-4f0b-a042-f73826be4ce9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ad6c906-4532-492e-ac4c-29c6465bb09e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5db2ac5-dfec-4c29-bd5f-dec74b1c5543",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "612dfbe0-3e79-4114-b886-ff982177a94d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82d43e3-9542-4563-81a5-c2100a0a447b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
