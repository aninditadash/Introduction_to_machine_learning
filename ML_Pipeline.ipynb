{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q788pGwAJCPp"
      },
      "source": [
        "# __Introduction to ML Pipelines__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prXug1h2rgSN"
      },
      "source": [
        "A machine learning pipeline (ML pipeline) is the systematic process of designing, developing and deploying a machine learning model. ML pipelines or ML workflows follow a series of steps that guide toward more efficient model development.\n",
        "\n",
        "The end-to-end machine learning pipeline comprises three stages:\n",
        "\n",
        "- __Data processing:__ Data scientists assemble and prepare the data that will be used to train the ML model. Phases in this stage include data collection, preprocessing, cleaning and exploration.\n",
        "- __Model development:__ Data practitioners choose or create a machine learning algorithm that fits the needs of the project. The algorithm is trained on the data from the previous step, and the resulting model is tested and validated until it is ready for use.\n",
        "- __Model deployment:__ Developers and software engineers deploy the model for real-world use, integrating it into a production environment and monitoring its performance.\n",
        "\n",
        "Machine learning workflows are a core building block for the larger discipline of machine learning operations (MLOps). Much of the process can be automated through various automated machine learning (AutoML) techniques that manage dependencies between stages and endpoints.\n",
        "\n",
        "https://www.ibm.com/think/topics/machine-learning-pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG7g16worgSO"
      },
      "source": [
        "## __Why sklearn pipelines?__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXsPrWcaJCPp"
      },
      "source": [
        "Pipelines provide an organized approach to managing your data preprocessing and modeling code. They combine preprocessing and modeling steps into a single, streamlined process.\n",
        "\n",
        "- **Cleaner Code**: Pipelines eliminate the need to manually manage training and validation data at each preprocessing step, reducing clutter and complexity.\n",
        "- **Fewer Bugs**: By bundling steps together, pipelines minimize the risk of misapplying or forgetting a preprocessing step.\n",
        "- **Easier to Productionize**: Pipelines simplify the transition from a prototype model to a scalable, deployable solution.\n",
        "\n",
        "**Syntax**:\n",
        "```python\n",
        "class sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "- A pipeline is a sequence of data transformers that can include a final predictor.\n",
        "- It lets you apply multiple preprocessing steps to your data in order, and optionally end with a predictor for modeling.\n",
        "- Each intermediate step in the pipeline must have fit and transform methods, while the final step only needs fit.\n",
        "- You can cache these transformers using the memory argument.\n",
        "- The pipeline's main goal is to combine multiple steps that can be cross-validated together and have their parameters adjusted.\n",
        "- You can set parameters for any step by using its name followed by a double underscore(__) and the parameter name.\n",
        "- You can replace any step's estimator with another estimator or remove a transformer by setting it to 'passthrough' or None."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCdpwEKfrgSO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VC4aZ_5rgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcCiCVp4rgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVGDrrh7rgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_hDd8ArgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHz4dWD_rgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AFlMuq9rgSP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KK2TLoSrgSP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlNSEYhorgSP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddQRwBIUJCPp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PN4_6toJCPp"
      },
      "source": [
        "## __Housing dataset (Regression)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVdMCrPirgSQ"
      },
      "source": [
        "### __Dataset description__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv4mr-BFrgSQ"
      },
      "source": [
        "The California housing dataset contains information on various socio-economic features of block groups in California. Each row in the dataset represents a single block group, and there are 20,640 observations, each with 10 attributes.\n",
        "\n",
        "The Features are as follows:\n",
        "1. Longitude: The longitude of the center of each block group in California.\n",
        "2. Latitude: The latitude of the center of each block group in California.\n",
        "3. Housing Median Age: The median age of the housing units in each block group.\n",
        "4. Total Rooms: The total number of rooms in the housing units in each block group.\n",
        "5. Total Bedrooms: The total number of bedrooms in the housing units in each block group.\n",
        "6. Population: The total population of the block group.\n",
        "7. Households: The total number of households in the block group.\n",
        "8. Median Income: The median income of the block group.\n",
        "9. Median House Value: The median value of the housing units in the block group.\n",
        "10. Ocean Proximity: The proximity of the block group to the ocean or other bodies of water."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPHQ1Rj8rgSQ"
      },
      "source": [
        "#### __Import the necessary libraries__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yTzzSp9mrgSQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ot_wlncrgSR"
      },
      "source": [
        "#### __Pre-processing the dataset__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uHc7WIJsJCPp",
        "outputId": "20153a47-e549-4144-be94-76816e223db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-1345711513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhousing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"housing.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.csv'"
          ]
        }
      ],
      "source": [
        "housing_data = pd.read_csv(\"housing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dY929xeLJCPp",
        "outputId": "46e02d4d-1398-457c-c5c8-08a96bb4fabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value ocean_proximity  \n",
              "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
              "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
              "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
              "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
              "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-689c0b5e-1d88-456d-b2f7-6ae4ec9a9d2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-689c0b5e-1d88-456d-b2f7-6ae4ec9a9d2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-689c0b5e-1d88-456d-b2f7-6ae4ec9a9d2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-689c0b5e-1d88-456d-b2f7-6ae4ec9a9d2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-244e3785-6977-4d61-b579-7ef3759d0bc0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-244e3785-6977-4d61-b579-7ef3759d0bc0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-244e3785-6977-4d61-b579-7ef3759d0bc0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "housing_data",
              "summary": "{\n  \"name\": \"housing_data\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.003531723502581,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571117,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.585557612111637,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          25.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582787,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.3850700740322,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1923,\n        \"samples\": [\n          1538.0,\n          1298.0,\n          1578.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1132.4621217653375,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          4169.0,\n          636.0,\n          3367.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.3297528316099,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8998217179452732,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12928,\n        \"samples\": [\n          5.0286,\n          2.0433,\n          6.1228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115395.6158744132,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3842,\n        \"samples\": [\n          194300.0,\n          379000.0,\n          230100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocean_proximity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<1H OCEAN\",\n          \"ISLAND\",\n          \"INLAND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "housing_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFxYo8Pw5JrC"
      },
      "outputs": [],
      "source": [
        "# Separate features and target variable\n",
        "# Assuming 'median_house_value' is the target variable in your dataset\n",
        "\n",
        "X = housing_data.drop('median_house_value', axis=1)\n",
        "y = housing_data['median_house_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0H6lIExJCPp"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmeWXusI5JrC",
        "outputId": "c5a47564-f778-4cec-bf5b-e7ed72820fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 14448 entries, 4722 to 7816\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           14448 non-null  float64\n",
            " 1   latitude            14448 non-null  float64\n",
            " 2   housing_median_age  14448 non-null  float64\n",
            " 3   total_rooms         14448 non-null  float64\n",
            " 4   total_bedrooms      14286 non-null  float64\n",
            " 5   population          14448 non-null  float64\n",
            " 6   households          14448 non-null  float64\n",
            " 7   median_income       14448 non-null  float64\n",
            " 8   ocean_proximity     14448 non-null  object \n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None \n",
            "\n",
            "longitude               0\n",
            "latitude                0\n",
            "housing_median_age      0\n",
            "total_rooms             0\n",
            "total_bedrooms        162\n",
            "population              0\n",
            "households              0\n",
            "median_income           0\n",
            "ocean_proximity         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Print info to check the structure of the training data\n",
        "\n",
        "print(X_train.info(), \"\\n\")\n",
        "print(X_train.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKqV5G9sJCPp"
      },
      "source": [
        "#### __Implementation for sklearn pipelines__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tuxhnoYJCPp"
      },
      "source": [
        "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/Sklearn_pipeline_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nY3QOuJCPp"
      },
      "source": [
        "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/Sklearn_pipeline_2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdtR51LVJCPp"
      },
      "source": [
        "#### __We need to perform following preprocessing steps before building the model__|\n",
        "\n",
        "1. Missing value treatment - 162 missing values in total_bedrooms(a numeric column)\n",
        "2. Dummy variable creation for categorical data\n",
        "3. Standardization of numeric variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XnT3bUdJCPq"
      },
      "outputs": [],
      "source": [
        "# import StandardScaler for standardization and OneHotEncoder for creating dummy variables\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# import SimpleImputer for missing value treatment\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# importing pipeline class. The Pipeline class is used to create a sequence of data processing steps.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# importing ColumnTransformer class to apply different preprocessing steps to different subsets of features in your dataset.\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjXlZ3znJCPq"
      },
      "source": [
        "##### __A note about ColumnTransformer__\n",
        "\n",
        "* ColumnTransformer class allows you to apply different preprocessing steps to different subsets of features in your dataset.\n",
        "* This is particularly useful when you have a mix of numerical and categorical data that require different types of preprocessing.\n",
        "* ColumnTransformer ensures that each column or group of columns gets the appropriate transformation before combining the results for further processing or modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLpxNEFaJCPq"
      },
      "source": [
        "### __Data preprocessing starts here:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBrCwrleJCPq"
      },
      "source": [
        "#### Steps to perform:\n",
        "    \n",
        "#### Step 1: Let's store the names of numeric and object type variables separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6jD0wYsJCPq"
      },
      "outputs": [],
      "source": [
        "# Set up preprocessing steps for numeric and categorical data\n",
        "\n",
        "housing_cat = X_train.select_dtypes(include='object').columns\n",
        "housing_num = X_train.select_dtypes(exclude='object').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-CyBWuGrgSS",
        "outputId": "f088f429-d94b-45cf-c1b5-0fec0b83202a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ocean_proximity'], dtype='object')"
            ]
          },
          "execution_count": 545,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEJVs14GrgSS",
        "outputId": "8ba101e7-ef24-4e98-b895-cc023e60eca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
              "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 547,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkgemfJ-JCPq"
      },
      "source": [
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDCfq3lJCPq"
      },
      "source": [
        "#### Step 2: Set-up sklearn pipeline for numeric variables. We need to perform missing value imputation and then standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KudVlvB3JCPq"
      },
      "outputs": [],
      "source": [
        "# Numeric variables pipeline\n",
        "# Here, null values will be imputed with the median value of the dataset\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQOz7FAPrgSd"
      },
      "outputs": [],
      "source": [
        "# Numeric variables pipeline\n",
        "# If we want to remove the rows with the null values (NOT WORKING)\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ijvgyUGrgSd"
      },
      "outputs": [],
      "source": [
        "# Categorical variables pipeline\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bj7McC2JCPq"
      },
      "source": [
        "The `num_pipeline` is a pipeline that preprocesses numerical data in two steps:\n",
        "\n",
        "- Imputation: Fills missing values using the median value of each column (SimpleImputer(strategy='median')).\n",
        "- Standardization: Scales the data to have a mean of 0 and a standard deviation of 1 (StandardScaler()).\n",
        "\n",
        "This pipeline ensures consistent and streamlined preprocessing of numerical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ch2NFiJCPq"
      },
      "source": [
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TuFRTCkJCPq"
      },
      "source": [
        "#### Step 3: Unified Data Preprocessing with Pipelines and ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQR14gk_JCPq"
      },
      "outputs": [],
      "source": [
        "# Unified preprocessing for both numeric and categorical data\n",
        "\n",
        "preprocessing = ColumnTransformer([\n",
        "    ('num', num_pipeline, housing_num),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), housing_cat)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeBHZ9flrgSe"
      },
      "outputs": [],
      "source": [
        "# Unified preprocessing for both numeric and categorical data\n",
        "\n",
        "preprocessing = ColumnTransformer([\n",
        "    ('num', num_pipeline, housing_num),\n",
        "    ('cat', cat_pipeline, housing_cat)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-A3phf1JCPq"
      },
      "source": [
        "The preprocessing step uses ColumnTransformer to apply different preprocessing pipelines to different types of data in the dataset:\n",
        "\n",
        " - Numerical Data: Applies num_pipeline to columns in housing_num, performing imputation and standardization.\n",
        " - Categorical Data: Applies OneHotEncoder to columns in housing_cat, converting categorical variables into a one-hot encoded format, ignoring unknown categories.\n",
        "\n",
        "This ensures that both numerical and categorical data are preprocessed appropriately within a single, unified framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaI1Qty4JCPq"
      },
      "source": [
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ0EBrXVJCPq"
      },
      "source": [
        "#### Let's check how the pipeline we have created works with the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX9c4geYJCPq"
      },
      "outputs": [],
      "source": [
        "# applying preprocessing pipeline to train data\n",
        "\n",
        "check_train = preprocessing.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t80hzsdJCPq",
        "outputId": "9eca293f-8b46-4968-b031-3b7ce1d59733"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.604388</td>\n",
              "      <td>-0.741523</td>\n",
              "      <td>1.536729</td>\n",
              "      <td>-0.620001</td>\n",
              "      <td>-0.715386</td>\n",
              "      <td>-0.790880</td>\n",
              "      <td>-0.721514</td>\n",
              "      <td>0.072853</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.798753</td>\n",
              "      <td>-0.862998</td>\n",
              "      <td>0.501005</td>\n",
              "      <td>-0.119890</td>\n",
              "      <td>-0.133529</td>\n",
              "      <td>0.218924</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.129574</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.845868</td>\n",
              "      <td>1.445014</td>\n",
              "      <td>-1.809456</td>\n",
              "      <td>0.736722</td>\n",
              "      <td>0.329095</td>\n",
              "      <td>0.298266</td>\n",
              "      <td>0.353837</td>\n",
              "      <td>0.825943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.279450</td>\n",
              "      <td>0.828299</td>\n",
              "      <td>-1.092417</td>\n",
              "      <td>-0.018491</td>\n",
              "      <td>-0.414919</td>\n",
              "      <td>-0.394171</td>\n",
              "      <td>-0.348165</td>\n",
              "      <td>3.519281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237318</td>\n",
              "      <td>-1.381600</td>\n",
              "      <td>1.457057</td>\n",
              "      <td>-0.847115</td>\n",
              "      <td>-0.739232</td>\n",
              "      <td>-0.702522</td>\n",
              "      <td>-0.747807</td>\n",
              "      <td>-0.986694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.604388 -0.741523  1.536729 -0.620001 -0.715386 -0.790880 -0.721514   \n",
              "1  0.798753 -0.862998  0.501005 -0.119890 -0.133529  0.218924 -0.043175   \n",
              "2 -0.845868  1.445014 -1.809456  0.736722  0.329095  0.298266  0.353837   \n",
              "3 -1.279450  0.828299 -1.092417 -0.018491 -0.414919 -0.394171 -0.348165   \n",
              "4  1.237318 -1.381600  1.457057 -0.847115 -0.739232 -0.702522 -0.747807   \n",
              "\n",
              "         7    8    9    10   11   12  \n",
              "0  0.072853  1.0  0.0  0.0  0.0  0.0  \n",
              "1  0.129574  1.0  0.0  0.0  0.0  0.0  \n",
              "2  0.825943  0.0  1.0  0.0  0.0  0.0  \n",
              "3  3.519281  0.0  0.0  0.0  1.0  0.0  \n",
              "4 -0.986694  0.0  0.0  0.0  0.0  1.0  "
            ]
          },
          "execution_count": 565,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# converting array to dataframe to have a better look at it\n",
        "\n",
        "check_train_df = pd.DataFrame(check_train)\n",
        "check_train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCQZ6iNgJCPq",
        "outputId": "f5d2ea66-b060-4fb9-e684-c9aaf70f836e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4     162\n",
              "5       0\n",
              "6       0\n",
              "7       0\n",
              "8       0\n",
              "9       0\n",
              "10      0\n",
              "11      0\n",
              "12      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 567,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# No NULL values found after pre-processing\n",
        "\n",
        "check_train_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkLLRW9-JCPq"
      },
      "source": [
        "#### __Observation:__\n",
        "\n",
        "1. Good to see all the missing values are treated\n",
        "2. numeric variables are standardised\n",
        "3. ocean_proximity is converted to dummy variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_03hcT-RJCPr"
      },
      "source": [
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "156uciNUJCPr"
      },
      "source": [
        "#### Step 4: Building Linear regression model and hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD6Lk-FQJCPr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDKVzBGqJCPr"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the Ridge regression model\n",
        "\n",
        "model = Ridge()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk6a6jk1JCPr"
      },
      "outputs": [],
      "source": [
        "# Build a Ridge regression model within a complete pipeline\n",
        "\n",
        "final_pipeline = Pipeline([\n",
        "    ('preprocessing', preprocessing),\n",
        "    ('model_ridge', model)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhILfy3zJCPr",
        "outputId": "dbf32d9d-1c3e-42fa-abd4-e76ef25ec743"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_ridge__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
              "        1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ])}"
            ]
          },
          "execution_count": 535,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the grid of hyperparameters to search\n",
        "# Note: You can set parameters for any step by using its name followed by a double underscore(__) and the parameter name.\n",
        "\n",
        "grid = dict()\n",
        "\n",
        "grid['model_ridge__alpha'] = np.arange(0.1,2.1,0.1)\n",
        "grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MgpLeo3JCPr",
        "outputId": "3e9fb7b8-6fcb-4620-8ad8-e81ebdc39481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 49789.360\n",
            "Config: {'model_ridge__alpha': 0.1}\n"
          ]
        }
      ],
      "source": [
        "# Create the GridSearchCV object\n",
        "\n",
        "search = GridSearchCV(estimator = final_pipeline, param_grid = grid, scoring = 'neg_mean_absolute_error',cv = 5, n_jobs= -1)\n",
        "\n",
        "# Fit GridSearchCV object to the training data\n",
        "\n",
        "results = search.fit(X_train, y_train)\n",
        "print('MAE: %.3f' % -results.best_score_)\n",
        "print('Config: %s' % results.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKlEIgQbJCPr"
      },
      "source": [
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lZXB7qZJCPr"
      },
      "source": [
        "#### Step 5: Using pipeline object to test the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgGxvzFf5JrF",
        "outputId": "19a43b36-0267-4f6b-ec99-2b1f50e33880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 50091.26322372467\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set using the trained model\n",
        "\n",
        "y_pred = search.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idA1M_uVJCPr"
      },
      "source": [
        "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/sklearn_pipeline_3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvo7LQPeInrT"
      },
      "source": [
        "### __Conclusion__\n",
        "\n",
        "Regression analysis is an essential method for examining and predicting variable relationships. In this lesson, we've delved into core types of regressionsimple linear, multiple linear, and polynomial regression.\n",
        "\n",
        "You've acquired skills to assess model performance using metrics like MSE, RMSE, and R-squared. Furthermore, we explored regularization techniques such as Lasso, Ridge, and ElasticNet to mitigate overfitting, and learned the importance of hyperparameter tuning for optimizing model parameters to enhance results.\n",
        "\n",
        "In conclusion, this lesson has provided a comprehensive exploration of regression through theoretical insights and hands-on applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC3X7e4CrgSf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}